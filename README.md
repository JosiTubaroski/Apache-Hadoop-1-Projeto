<div> 
<p><a href="https://github.com/JosiTubaroski/Introducao_Engenharia_Dados/blob/main/README.md">Introdução a Engenharia de Dados</a></p>
</div> 

# Qual o primeiro projeto a utilizar o hadoop?


O primeiro projeto a utilizar o Hadoop foi o Nutch, um motor de busca de código aberto.

### Origem do Uso no Nutch

- Desafio no Nutch: O projeto Nutch, iniciado por Doug Cutting e Mike Cafarella em 2002, buscava construir uma alternativa de código aberto aos mecanismos de busca dominantes,
  como o Google.  Porém, à medida que o Nutch crescia, os desenvolvedores enfrentavam dificuldades para armazenar e processar grandes volumes de dados indexados de páginas da web.

- Inspiração dos Artigos do Google: Após a publicação dos artigos do Google File System (GFS) em 2003 e do MapReduce em 2004, Doug Cutting e Mike Cafarella perceberam que poderiam implementar soluções semelhantes para resolver os problemas do Nutch.

- Adaptação das Ideias: Em 2005, eles implementaram o MapReduce e um sistema de arquivos distribuído (que mais tarde se tornou o HDFS) dentro do Nutch.

### Separação do Hadoop do Nutch

- Em 2006, as partes de processamento distribuído (MapReduce) e armazenamento (HDFS) do Nutch foram extraídas e transformadas em um projeto independente chamado Hadoop.
- A separação permitiu que o Hadoop fosse usado como uma solução genérica para outros problemas de Big Data, além do mecanismo de busca.

## Importância do Nutch

O uso inicial no Nutch mostrou a viailidade do Hadoop para lidar com grandes volumes de dados de forma escalável e eficiente, abrindo caminho para sua adoção em outras áreas e sua popularização como um framework fundamental para Big Data.
